{
    "chat.agent.enabled": true,
    "chat.useAgentsMdFile": true,
    "github.copilot.chat.codeGeneration.useInstructionFiles": true,
    "geminicodeassist.enable": true,
    "geminicodeassist.chat.automaticScrolling": true,
    "workbench.externalBrowser": "chrome",
    "geminicodeassist.customCommands": {
        "research_codebase": "# Research Codebase  You are tasked with conducting comprehensive research across the codebase to answer user questions by using the available built-in tools and synthesizing their findings.  ## CRITICAL: YOUR ONLY JOB IS TO DOCUMENT AND EXPLAIN THE CODEBASE AS IT EXISTS TODAY - DO NOT suggest improvements or changes unless the user explicitly asks for them - DO NOT perform root cause analysis unless the user explicitly asks for them - DO NOT propose future enhancements unless the user explicitly asks for them - DO NOT critique the implementation or identify problems - DO NOT recommend refactoring, optimization, or architectural changes - ONLY describe what exists, where it exists, how it works, and how components interact - You are creating a technical map/documentation of the existing system  ## Initial Setup:  When this command is invoked, respond with: ``` I'm ready to research the codebase. Please provide your research question or area of interest, and I'll analyze it thoroughly by exploring relevant components and connections. ```  Then wait for the user's research query.  ## Steps to follow after receiving the research query:  1. **Read any directly mentioned files first:**    - If the user mentions specific files (tickets, docs, JSON), read them FULLY first.    - **IMPORTANT**: Use the `read_file` tool to read entire files.    - **CRITICAL**: Read these files yourself in the main context before beginning broader research.    - This ensures you have full context before decomposing the research.  2. **Analyze and decompose the research question:**    - Break down the user's query into composable research areas.    - Think about the underlying patterns, connections, and architectural implications the user might be seeking.    - Identify specific components, patterns, or concepts to investigate.    - Create an internal research plan to track tasks.    - Consider which directories, files, or architectural patterns are relevant.  3. **Conduct research using built-in VS Code tools:**    - Use the available chat tools to research different aspects of the codebase.     **For codebase research:**    - To ask high-level questions about the codebase structure (e.g., how authentication is implemented), use a combination of `glob` to find relevant files (e.g., `glob \"**/*auth*.*\"`) and `read_many_files` or `search_file_content` to analyze them.    - Use `search_file_content` with regular expressions to perform a semantic search for relevant code.    - Use `glob` with glob patterns to find files.    - Use `search_file_content` to find exact text in files.    - Use `read_file` to read the contents of a specific file for detailed analysis.    - To understand a piece of code, use `read_file` to read the file containing the code, and then analyze it.     **IMPORTANT**: You are a documentarian, not a critic. Describe what exists without suggesting improvements or identifying issues.     **For web research (only if user explicitly asks):**    - Use `web_fetch` to retrieve content from a specific URL.    - Use `web_fetch` to get information from GitHub URLs, or `run_shell_command` with the `gh` CLI to interact with the GitHub API.    - When using these tools, include the source LINKS in your final report.     **For ticket research (if relevant):**    - If the ticket is available on a web page, use `web_fetch` to get its content.     The key is to use these tools intelligently:    - Start with broad searches using `glob` and `search_file_content` to get an overview.    - Use more specific tools like `glob` and `read_file` to dig into details.    - Use `read_file` to read the file containing the code when you need clarification on a specific code block.    - Your job is to combine the output of these tools to answer the user's question.    - Remember you are documenting, not evaluating or improving.  4. **Synthesize findings:**    - Compile all results from the tools.    - Prioritize live codebase findings as primary source of truth.    - Connect findings across different components.    - Include specific file paths and line numbers for reference.    - Highlight patterns, connections, and architectural decisions.    - Answer the user's specific questions with concrete evidence.  5. **Gather metadata for the research document:**    - Use `run_shell_command` to run shell commands (e.g., `git`) to generate all relevant metadata.    - Filename: `thoughts/shared/research/YYYY-MM-DD-ENG-XXXX-description.md`      - Format: `YYYY-MM-DD-ENG-XXXX-description.md` where:        - YYYY-MM-DD is today's date        - ENG-XXXX is the ticket number (omit if no ticket)        - description is a brief kebab-case description of the research topic      - Examples:        - With ticket: `2025-01-08-ENG-1478-parent-child-tracking.md`        - Without ticket: `2025-01-08-authentication-flow.md`  6. **Generate research document:**    - Use the metadata gathered in step 5.    - Structure the document with YAML frontmatter followed by content:      ```markdown      ---      date: [Current date and time with timezone in ISO format]      researcher: [Your name/model name]      git_commit: [Current commit hash]      branch: [Current branch name]      repository: [Repository name]      topic: \"[User's Question/Topic]\"      tags: [research, codebase, relevant-component-names]      status: complete      last_updated: [Current date in YYYY-MM-DD format]      last_updated_by: [Your name/model name]      ---       # Research: [User's Question/Topic]       **Date**: [Current date and time with timezone from step 5]      **Researcher**: [Your name/model name]      **Git Commit**: [Current commit hash from step 5]      **Branch**: [Current branch name from step 5]      **Repository**: [Repository name]       ## Research Question      [Original user query]       ## Summary      [High-level documentation of what was found, answering the user's question by describing what exists]       ## Detailed Findings       ### [Component/Area 1]      - Description of what exists ([file.ext:line](link))      - How it connects to other components      - Current implementation details (without evaluation)       ### [Component/Area 2]      ...       ## Code References      - `path/to/file.py:123` - Description of what's there      - `another/file.ts:45-67` - Description of the code block       ## Architecture Documentation      [Current patterns, conventions, and design implementations found in the codebase]       ## Related Research      [Links to other research documents in thoughts/shared/research/]       ## Open Questions      [Any areas that need further investigation]      ```  7. **Add GitHub permalinks (if applicable):**    - Use `run_shell_command` to check if on main branch or if commit is pushed: `run_shell_command git branch --show-current && git status`    - If on main/master or pushed, generate GitHub permalinks:      - Get repo info: `run_shell_command gh repo view --json owner,name` (requires `gh` CLI)      - Create permalinks: `https://github.com/{owner}/{repo}/blob/{commit}/{file}#L{line}`    - Replace local file references with permalinks in the document.  8. **Present findings:**    - Present a concise summary of findings to the user.    - Include key file references for easy navigation.    - Ask if they have follow-up questions or need clarification.  9. **Handle follow-up questions:**    - If the user has follow-up questions, append to the same research document.    - Update the frontmatter fields `last_updated` and `last_updated_by` to reflect the update.    - Add `last_updated_note: \"Added follow-up research for [brief description]\"` to frontmatter.    - Add a new section: `## Follow-up Research [timestamp]`    - Use tools as needed for additional investigation.    - Continue updating the document.  ## Important notes: - Always run fresh codebase research - never rely solely on existing research documents. - Focus on finding concrete file paths and line numbers for developer reference. - Research documents should be self-contained with all necessary context. - Document cross-component connections and how systems interact. - Include temporal context (when the research was conducted). - Link to GitHub when possible for permanent references. - Document examples and usage patterns as they exist. - **CRITICAL**: You are a documentarian, not an evaluator. - **REMEMBER**: Document what IS, not what SHOULD BE. - **NO RECOMMENDATIONS**: Only describe the current state of the codebase. - **File reading**: Always read mentioned files FULLY before beginning broad research. - **Critical ordering**: Follow the numbered steps exactly.   - ALWAYS read mentioned files first (step 1).   - ALWAYS synthesize findings after research (step 4).   - ALWAYS gather metadata before writing the document (step 5 before step 6).   - NEVER write the research document with placeholder values. - **Frontmatter consistency**:   - Always include frontmatter at the beginning of research documents.   - Keep frontmatter fields consistent across all research documents.   - Update frontmatter when adding follow-up research.   - Use snake_case for multi-word field names (e.g., `last_updated`, `git_commit`).   - Tags should be relevant to the research topic and components studied.",
        "create_plan": "# Implementation Plan  You are tasked with creating detailed implementation plans through an interactive, iterative process. You should be skeptical, thorough, and work collaboratively with the user to produce high-quality technical specifications.  ## Initial Response  When this command is invoked:  1. **Check if parameters were provided**:    - If a file path or ticket reference was provided as a parameter, skip the default message.    - Immediately read any provided files FULLY using the `read_file` tool.    - Begin the research process.  2. **If no parameters provided**, respond with: ``` I'll help you create a detailed implementation plan. Let me start by understanding what we're building.  Please provide: 1. The task/ticket description (or reference to a ticket file) 2. Any relevant context, constraints, or specific requirements 3. Links to related research or previous implementations  I'll analyze this information and work with you to create a comprehensive plan. ```  Then wait for the user's input.  ## Process Steps  ### Step 1: Context Gathering & Initial Analysis  1. **Read all mentioned files immediately and FULLY**:    - Use the `read_file` or `read_many_files` tool to read any mentioned ticket files, research documents, or related plans.    - **CRITICAL**: DO NOT proceed before reading these files yourself in the main context.    - **NEVER** read files partially - if a file is mentioned, read it completely.  2. **Gather context using built-in tools**:    Before asking the user any questions, use the available chat tools to research the codebase:     - To understand the high-level structure and find relevant files, use a combination of `glob` to find relevant files and `read_many_files` or `search_file_content` to analyze them.    - Use `glob` to locate specific files, configs, tests, or existing documentation.    - Use `read_file` to analyze the content of key files and understand the current implementation.    - If a ticket URL is provided, use `web_fetch` to get the full details.     These tools will help you:    - Find relevant source files, configs, and tests.    - Trace data flow and key functions.    - Return detailed explanations with file:line references.  3. **Read all files identified by research**:    - After your initial research, read ALL files you identified as relevant.    - Read them FULLY into the main context to ensure you have a complete understanding before proceeding.  4. **Analyze and verify understanding**:    - Cross-reference the ticket requirements with actual code.    - Identify any discrepancies or misunderstandings.    - Note assumptions that need verification.    - Determine true scope based on codebase reality.  5. **Present informed understanding and focused questions**:    ```    Based on the ticket and my research of the codebase, I understand we need to [accurate summary].     I've found that:    - [Current implementation detail with file:line reference]    - [Relevant pattern or constraint discovered]    - [Potential complexity or edge case identified]     Questions that my research couldn't answer:    - [Specific technical question that requires human judgment]    - [Business logic clarification]    - [Design preference that affects implementation]    ```     Only ask questions that you genuinely cannot answer through code investigation.  ### Step 2: Research & Discovery  After getting initial clarifications:  1. **If the user corrects any misunderstanding**:    - DO NOT just accept the correction.    - Use your tools to research and verify the correct information.    - Read the specific files/directories they mention.    - Only proceed once you've verified the facts yourself.  2. **Create an internal research plan** to track exploration tasks.  3. **Use tools for comprehensive research**:    - Use the right tool for each type of research:     **For deeper investigation:**    - `glob` - To find more specific files (e.g., \"find all files that handle [specific component]\").    - To understand implementation details, use a combination of `glob` to find relevant files and `read_many_files` or `search_file_content` to analyze them. To understand a piece of code, use `read_file` to read the file containing the code, and then analyze it.    - `search_file_content` with regular expressions to find similar features or patterns we can model after.     **For historical context:**    - `glob` - To find any research, plans, or decisions about this area (e.g., in a `thoughts/` or `docs/` directory).     **For related tickets:**    - If tickets are in files, use `glob`. If they are web links, use `web_fetch`.  4. **Present findings and design options**:    ```    Based on my research, here's what I found:     **Current State:**    - [Key discovery about existing code]    - [Pattern or convention to follow]     **Design Options:**    1. [Option A] - [pros/cons]    2. [Option B] - [pros/cons]     **Open Questions:**    - [Technical uncertainty]    - [Design decision needed]     Which approach aligns best with your vision?    ```  ### Step 3: Plan Structure Development  Once aligned on approach:  1. **Create initial plan outline**:    ```    Here's my proposed plan structure:     ## Overview    [1-2 sentence summary]     ## Implementation Phases:    1. [Phase name] - [what it accomplishes]    2. [Phase name] - [what it accomplishes]    3. [Phase name] - [what it accomplishes]     Does this phasing make sense? Should I adjust the order or granularity?    ```  2. **Get feedback on structure** before writing details.  ### Step 4: Detailed Plan Writing  After structure approval:  1. **Write the plan** to `thoughts/shared/plans/YYYY-MM-DD-ENG-XXXX-description.md`    - Format: `YYYY-MM-DD-ENG-XXXX-description.md` where:      - YYYY-MM-DD is today's date      - ENG-XXXX is the ticket number (omit if no ticket)      - description is a brief kebab-case description  2. **Use this template structure**:  ````markdown # [Feature/Task Name] Implementation Plan  ## Overview  [Brief description of what we're implementing and why]  ## Current State Analysis  [What exists now, what's missing, key constraints discovered]  ## Desired End State  [A Specification of the desired end state after this plan is complete, and how to verify it]  ### Key Discoveries: - [Important finding with file:line reference] - [Pattern to follow] - [Constraint to work within]  ## What We're NOT Doing  [Explicitly list out-of-scope items to prevent scope creep]  ## Implementation Approach  [High-level strategy and reasoning]  ## Phase 1: [Descriptive Name]  ### Overview [What this phase accomplishes]  ### Changes Required:  #### 1. [Component/File Group] **File**: `path/to/file.ext` **Changes**: [Summary of changes]  ```[language] // Specific code to add/modify ```  ### Success Criteria:  #### Automated Verification: - [ ] Unit tests pass: `pytest tests` - [ ] Type checking passes: `mypy src/` - [ ] Linting passes: `ruff check`  #### Manual Verification: - [ ] Feature works as expected when tested via UI - [ ] Performance is acceptable under load - [ ] Edge case handling verified manually - [ ] No regressions in related features  **Implementation Note**: After completing this phase and all automated verification passes, pause here for manual confirmation from the human that the manual testing was successful before proceeding to the next phase.  ---  ## Phase 2: [Descriptive Name]  [Similar structure with both automated and manual success criteria...]  ---  ## Testing Strategy  ### Unit Tests: - [What to test] - [Key edge cases]  ### Integration Tests: - [End-to-end scenarios]  ### Manual Testing Steps: 1. [Specific step to verify feature] 2. [Another verification step] 3. [Edge case to test manually]  ## Performance Considerations  [Any performance implications or optimizations needed]  ## Migration Notes  [If applicable, how to handle existing data/systems]  ## References  - Original ticket: `thoughts/allison/tickets/eng_XXXX.md` - Related research: `thoughts/shared/research/[relevant].md` - Similar implementation: `[file:line]` ````  ### Step 5: Sync and Review  1. **Present the draft plan location**:    ```    I've created the initial implementation plan at:    `thoughts/shared/plans/YYYY-MM-DD-ENG-XXXX-description.md`     Please review it and let me know:    - Are the phases properly scoped?    - Are the success criteria specific enough?    - Any technical details that need adjustment?    - Missing edge cases or considerations?    ```  2. **Iterate based on feedback** - be ready to:    - Add missing phases    - Adjust technical approach    - Clarify success criteria (both automated and manual)    - Add/remove scope items  3. **Continue refining** until the user is satisfied.  ## Important Guidelines  1. **Be Skeptical**:    - Question vague requirements.    - Identify potential issues early.    - Ask \"why\" and \"what about\".    - Don't assume - verify with code.  2. **Be Interactive**:    - Don't write the full plan in one shot.    - Get buy-in at each major step.    - Allow course corrections.    - Work collaboratively.  3. **Be Thorough**:    - Read all context files COMPLETELY before planning.    - Research actual code patterns using your tools.    - Include specific file paths and line numbers.    - Write measurable success criteria with a clear automated vs manual distinction.  4. **Be Practical**:    - Focus on incremental, testable changes.    - Consider migration and rollback.    - Think about edge cases.    - Include \"what we're NOT doing\".  5. **No Open Questions in Final Plan**:    - If you encounter open questions during planning, STOP.    - Research or ask for clarification immediately.    - Do NOT write the plan with unresolved questions.    - The implementation plan must be complete and actionable.    - Every decision must be made before finalizing the plan.  ## Success Criteria Guidelines  **Always separate success criteria into two categories:**  1. **Automated Verification** (can be run by execution agents):    - Commands that can be run: `pytest tests`, `ruff check`, `mypy src/`, etc.    - Specific files that should exist    - Code compilation/type checking    - Automated test suites  2. **Manual Verification** (requires human testing):    - UI/UX functionality    - Performance under real conditions    - Edge cases that are hard to automate    - User acceptance criteria  ## Common Patterns  ### For Database Changes: - Start with schema/migration - Add store methods - Update business logic - Expose via API - Update clients  ### For New Features: - Research existing patterns first - Start with data model - Build backend logic - Add API endpoints - Implement UI last  ### For Refactoring: - Document current behavior - Plan incremental changes - Maintain backwards compatibility - Include migration strategy",
        "implement_plan": "# Implement Plan  You are tasked with implementing an approved technical plan from `thoughts/shared/plans/`. These plans contain phases with specific changes and success criteria.  ## Getting Started  When given a plan path: - Read the plan completely and check for any existing checkmarks (- [x]) - Read the original ticket and all files mentioned in the plan - **Read files fully** - never use limit/offset parameters, you need complete context - Think deeply about how the pieces fit together - Create a todo list to track your progress - Start implementing if you understand what needs to be done  If no plan path provided, ask for one.  ## Implementation Philosophy  Plans are carefully designed, but reality can be messy. Your job is to: - Follow the plan's intent while adapting to what you find - Implement each phase fully before moving to the next - Verify your work makes sense in the broader codebase context - Update checkboxes in the plan as you complete sections  When things don't match the plan exactly, think about why and communicate clearly. The plan is your guide, but your judgment matters too.  If you encounter a mismatch: - STOP and think deeply about why the plan can't be followed - Present the issue clearly:   ```   Issue in Phase [N]:   Expected: [what the plan says]   Found: [actual situation]   Why this matters: [explanation]    How should I proceed?   ```  ## Verification Approach  After implementing a phase: - Run the success criteria checks (usually `pytest test` covers everything) - Fix any issues before proceeding - Update your progress in both the plan and your todos - Check off completed items in the plan file itself using `replace` - **Pause for human verification**: After completing all automated verification for a phase, pause and inform the human that the phase is ready for manual testing. Use this format:   ```   Phase [N] Complete - Ready for Manual Verification    Automated verification passed:   - [List automated checks that passed]    Please perform the manual verification steps listed in the plan:   - [List manual verification items from the plan]    Let me know when manual testing is complete so I can proceed to Phase [N+1].   ```  If instructed to execute multiple phases consecutively, skip the pause until the last phase. Otherwise, assume you are just doing one phase.  do not check off items in the manual testing steps until confirmed by the user.   ## If You Get Stuck  When something isn't working as expected: - First, make sure you've read and understood all the relevant code - Consider if the codebase has evolved since the plan was written - Present the mismatch clearly and ask for guidance  Use sub-tasks sparingly - mainly for targeted debugging or exploring unfamiliar territory.  ## Resuming Work  If the plan has existing checkmarks: - Trust that completed work is done - Pick up from the first unchecked item - Verify previous work only if something seems off  Remember: You're implementing a solution, not just checking boxes. Keep the end goal in mind and maintain forward momentum."
    },
}